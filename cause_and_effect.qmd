# Cause and Effect {#sec-cause-and-effect}

In this first part of the material, we are going to take a close look at **the** fundamental issue we care about when performing a scientific experiment: _cause and effect_. For this we need to be aware of something called _Causal Inference_, which is a large and separate field of study, but from which we will borrow some key ideas.

## The Problem With Statistics

Causal inference attempts to put science before statistics, or at least to make statistics work to give us useful scientific outputs. The reason we need something like causal inference is this: **the reasons for carrying out a statistical analysis are not present in the data.**

::: {.callout-important}
## The reasons for carrying out a statistical analysis are not present in the data

What do we mean by this statement?

As an example, consider a statistical question where you have two sets of numbers: {10, 11, 12} and {14, 15, 16}, and you ask: are the averages of these two sets different from each other?

As you will recall from your introductory statistics courses, we can always calculate the means and standard deviations of the two sets of numbers, and perform a _t_-test to calculate a proability that we should _reject a null hypothesis_ of the means being equal. So we can answer the question: "Are the means of these two sets of values statistically different from each other?". 

But we're usually not asking that question in isolation. In an experiment, those numbers represent something in the real world, and in which we're interested. We want to know what is the _scientific insight that is gained_? Maybe it's something like:

1. the number of people who vote in an election before and after a bribe is offered
2. the number of mice that survive a condition, after some drug intervention
3. reaction times in an individual before and after drinking alcohol

The point is, **we can't tell what the numbers represent, or what any differences mean, from the data alone!** We cannot look at the numbers alone and extract the causes of the data.

> "No causes in, no causes out." - _Nancy Cartwright_, @Cartwright2011-jb
:::

Statistical models are only devices that process data to provide estimates. To understand what the data are telling us, and for statistical analysis to give us scientific insight, we need additional information: _scientific (causal) models_. 

## What is a causal model?

A causal model is a system where if we change only one variable we will modify some variables in the model. The variable we change is called a _cause_ and the variables that respond suffer the _effects_.

::: {.callout-warning}
## Correlation does not imply causation

You will probably have **correctly** heard phrases like "_correlation does not imply causation_" in reference to the observation that just because you can identify two values apparently changing together, that doesn't mean that the change in one value _causes_ the other to change. The relationship might be the reverse of what you think (after all, an association between two sets values could run in either direction - the direction is not evident from the data alone), or it may be pure coincidence. There's even a whole website dedicated to such [spurious correlations](https://www.tylervigen.com/spurious-correlations).

It turns out that _causation does not imply correlation_ either, but this is a complex topic that we don't have time to get into in a single workshop about experimental design.

The statment "_correlation does not imply causation_" is often used dismissively to demean the role of statistics, but that's unfair. It _is_ possible to estimate causal effects using statistics, but **all of the information about causal relationships comes from the researcher**. 
:::

When we talk about _causes_ and _effects_ in the context of a _statistical association_ (such as correlation) it is usually intended to mean one of two things:

1. **The estimate or prediction of the consequences of an intervention** - and in an experimental context you are often aiming to set up a system where a single intervention of interest (such as administration of a drug) is being made, and the consequences measured.
2. **The imputation of a missing observation** - such that, if you have a causal model, you can play "what if?" games by substituting values which you have not directly measured to see what changes in the system might result. This allows us to construct _unobserved counterfactual outcomes_.

::: {.callout-tip collapse="true"}
## A tangible example

If you are aware of, or propose, a _causal relationship_ you are expressing the belief that you can predict the consequences of an intervention.

For example, if you look out of the window and see trees swaying, and there is some wind, you know the ttwo are connected because the _wind is causing the trees to sway_, not because the trees are moving and creating the wind. But, if you measured windspeed and tree movement, there would be only a _statistical association_: there would be nothing in the data itself to tell you which was the cause and which was the effect. But you _know_ the causal relationship and the nature of the intervention: **wind makes trees sway**. If you climbed into the tree and rocked it, you would not generate wind. But if you measured the amount by which a tree sways, you could make an estimate of the prevailing windspeed. 
:::

All information about causal relationships comes from **the scientists' understanding of the world** or, more to the point, **their understanding of the experimental system**.

### Your beliefs about the system are the causal model

The assumptions and beliefs you have that cause you to consider setting up your experiment are a kind of causal model. 

::: {.callout-note}
For instance, if you believe that reaction times get slower when someone has drunk alcohol, then your causal model is that _alcohol consumption_ **causes** _change in reaction times_. 
:::

You would design your experiment to enable measurements of alcohol consumption and reaction time to be measured, and you might look to find a statistical association. But if you _did_ find a statistical association, your causal interpretation (e.g. that "reaction time slows with increasing alcohol dose") would be the result of your beliefs about the experimental system, not a result of simply running statistical analysis on the dataset.

![Experimental design, causal (statistical) inference, and the (statistical) description of a system all depend on the existence of a well-constructed scientific (causal) model. [Meme](https://github.com/rmcelreath/stat_rethinking_2023) by Richard McElreath, CC0](assets/images/inference_spiderman.jpg){#fig-spiderman-causal width=80%}

## We need to talk about DAGs

A _DAG_ is a _Directed Acyclic Graph_. DAGs are abstract mathematical structures that are extremely useful in many contexts. But, for our purposes, what is important is that they can be used to describe the causal relationships you believe are present in your experimental system. Describing your beliefs as a DAG has advantages:

1. **It is a concise way to express your understanding of the experiment clearly**
  - It is easy to visualise and share with others, so they can understand your view of the experiment
2. **The structure of a DAG can be analysed to suggest an appropriate statistical model**
  - A DAG's structure can suggest which controls to use in an experiment, and what statistical analysis might be most appropriate
  - Analysis of the DAG structure can tell you what can (and what _cannot_) be logically decided by the experiment, without having to make additional assumptions

We will introduce DAGs for experimental design in more detail, in the next section.